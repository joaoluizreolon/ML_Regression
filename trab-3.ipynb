{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"Data/winequality-red.csv\")\n",
    "df_dados = pd.DataFrame(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data and split it into train, validation and test sets\n",
    "def ShuffleuSplit(df_dados):\n",
    "    # shuffle data to avoid bias\n",
    "    df_dados = shuffle(df_dados)\n",
    "\n",
    "    # separe the last column in another variable\n",
    "    df_dados_without_class = df_dados.drop(columns=[\"quality\"])\n",
    "\n",
    "\n",
    "    # split the data into train, validation and test sets\n",
    "    x_treino, x_temp, y_treino, y_temp = train_test_split(\n",
    "        df_dados_without_class,\n",
    "        df_dados[\"quality\"],\n",
    "        test_size=0.5,\n",
    "    )\n",
    "    x_validacao, x_teste, y_validacao, y_teste = train_test_split(\n",
    "        x_temp, y_temp, test_size=0.5\n",
    "    )\n",
    "\n",
    "    # print(\"Treino\")\n",
    "    # x_treino.info()\n",
    "    # y_treino.info()\n",
    "\n",
    "    # print(\"\\nValidação\")\n",
    "    # x_validacao.info()\n",
    "    # y_validacao.info()\n",
    "\n",
    "    # print(\"\\nTeste\")\n",
    "    # x_teste.info()\n",
    "    # y_teste.info()\n",
    "    \n",
    "    return (\n",
    "        x_treino,\n",
    "        y_treino,\n",
    "        x_validacao,\n",
    "        y_validacao,\n",
    "        x_teste,\n",
    "        y_teste,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Correlation in df_dados\n",
    "cor = df_dados.corr()\n",
    "\n",
    "#Print the heat map\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Correlation Heatmap of Wine Quality Attributes')\n",
    "a = sns.heatmap(cor, square=True, annot=True, fmt='.2f', linecolor='black')\n",
    "a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "a.set_yticklabels(a.get_yticklabels(), rotation=30)\n",
    "plt.show()\n",
    "#Create an txt archive to save\n",
    "f = open(\"Data/df_dados.txt\", \"w\")\n",
    "\n",
    "#Save the matrix of correlation in txt archive\n",
    "f.write(\"Matriz de correlação do df_dados: \\n\")\n",
    "f.write(str(cor))\n",
    "f.write(\"\\n\")\n",
    "#Save the size of df_dados in txt archive\n",
    "f.write(\"Tamanho do df_dados: \\n\")\n",
    "f.write(str(df_dados.shape))\n",
    "f.write(\"\\n\")\n",
    "#Save the dimension of df_dados in txt archive\n",
    "f.write(\"Dimensão do df_dados: \\n\")\n",
    "f.write(str(df_dados.ndim))\n",
    "f.write(\"\\n\")\n",
    "#Save the number of classes in df_dados in txt archive\n",
    "f.write(\"Número de classes do df_dados: \\n\")\n",
    "f.write(str(df_dados['quality'].nunique()))\n",
    "f.write(\"\\n\")\n",
    "#Save the type of atributtes in df_dados in txt archive\n",
    "f.write(\"Tipo dos atributos do df_dados: \\n\")\n",
    "f.write(str(df_dados.dtypes))\n",
    "f.write(\"\\n\")\n",
    "#Save the average values ​​of each attribute in df_dados in txt archive\n",
    "f.write(\"Valor médio de cada atributo do df_dados: \\n\")\n",
    "f.write(str(df_dados.mean()))\n",
    "f.write(\"\\n\")\n",
    "#Save the maximum values ​​of each attribute in df_dados in txt archive\n",
    "f.write(\"Valor máximo de cada atributo do df_dados: \\n\")\n",
    "f.write(str(df_dados.max()))\n",
    "f.write(\"\\n\")\n",
    "#Save the minimum values ​​of each attribute in df_dados in txt archive\n",
    "f.write(\"Valor mínimo de cada atributo do df_dados: \\n\")\n",
    "f.write(str(df_dados.min()))\n",
    "f.write(\"\\n\")\n",
    "#Close the txt archive\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def grid_search_KNN_regression(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    best_rmse = float('inf')\n",
    "    best_k = -1\n",
    "    best_distance_metric = \"\"\n",
    "    best_KNN = None\n",
    "\n",
    "    for k in range(1, 50, 2):\n",
    "        for distance_metric in [\"uniform\", \"distance\"]:\n",
    "            knn_instance = KNeighborsRegressor(\n",
    "                n_neighbors=k, weights=distance_metric\n",
    "            )\n",
    "            knn_instance.fit(x_treino, y_treino)\n",
    "            knn_validation_pred = knn_instance.predict(x_validacao)\n",
    "            mse = mean_squared_error(y_validacao, knn_validation_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_k = k\n",
    "                best_distance_metric = distance_metric\n",
    "                best_KNN = knn_instance\n",
    "\n",
    "    return best_KNN, best_k, best_distance_metric\n",
    "\n",
    "\n",
    "def KNN_regression(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_KNN, best_k, best_distance_metric = grid_search_KNN_regression(\n",
    "        x_treino, y_treino, x_validacao, y_validacao\n",
    "    )\n",
    "\n",
    "    knn_test_pred = best_KNN.predict(x_teste)\n",
    "    test_mse = mean_squared_error(y_teste, knn_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "    return test_rmse, best_KNN, best_k, best_distance_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def grid_search_SVM_regression(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    param_grid = {\n",
    "        \"C\": [0.1, 1.0, 10.0],  # Define C values\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    }\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_SVM = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        svm_instance = SVR(**params)\n",
    "        svm_instance.fit(x_treino, y_treino)\n",
    "        svm_validation_pred = svm_instance.predict(x_validacao)\n",
    "        mse = mean_squared_error(y_validacao, svm_validation_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = params\n",
    "            best_SVM = svm_instance\n",
    "\n",
    "    return best_SVM, best_params\n",
    "\n",
    "\n",
    "def SVM_regression(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_SVM, best_params = grid_search_SVM_regression(\n",
    "        x_treino, y_treino, x_validacao, y_validacao\n",
    "    )\n",
    "\n",
    "    svm_test_pred = best_SVM.predict(x_teste)\n",
    "    test_mse = mean_squared_error(y_teste, svm_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "    return test_rmse, best_SVM, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def grid_search_MLP_regression(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    param_grid = {\n",
    "        \"hidden_layer_sizes\": [\n",
    "            (100,),\n",
    "            (50, 50),\n",
    "            (100, 50, 25),\n",
    "        ],  # Define hidden_layer_sizes\n",
    "        \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "        \"max_iter\": [1000, 2000],  # Define max_iter values\n",
    "        \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    }\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_MLP = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        mlp_instance = MLPRegressor(**params)\n",
    "        mlp_instance.fit(x_treino, y_treino)\n",
    "        mlp_validation_pred = mlp_instance.predict(x_validacao)\n",
    "        mse = mean_squared_error(y_validacao, mlp_validation_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = params\n",
    "            best_MLP = mlp_instance\n",
    "\n",
    "    return best_MLP, best_params\n",
    "\n",
    "\n",
    "def MLP_regression(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_MLP, best_params = grid_search_MLP_regression(\n",
    "        x_treino, y_treino, x_validacao, y_validacao\n",
    "    )\n",
    "\n",
    "    mlp_test_pred = best_MLP.predict(x_teste)\n",
    "    test_mse = mean_squared_error(y_teste, mlp_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "    return test_rmse, best_MLP, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Create a function to calculate the multiple linear regression and retorn the root mean-square error\n",
    "def LinearRegressionMultiple(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    #Create a linear regression model\n",
    "    model = LinearRegression()\n",
    "    #Train the model\n",
    "    model.fit(x_treino, y_treino)\n",
    "    #Predict the model\n",
    "    y_pred = model.predict(x_validacao)\n",
    "    #Calculate the root mean-square error using\n",
    "    rmse = np.sqrt(np.mean((y_pred - y_validacao) ** 2))\n",
    "    #Return the root mean-square error\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns=[\"KNR\", \"SVR\", \"MLP\", \"RF\", \"GB\", \"MLR\"])\n",
    "\n",
    "knr_best_params = pd.DataFrame(columns=[\"K\", \"Distance Metric\"])\n",
    "svr_best_params = pd.DataFrame(\n",
    "    columns=[\"kernel\", \"C\"]\n",
    ")\n",
    "mlp_best_params = pd.DataFrame(\n",
    "    columns=[\"hidden_layer_sizes\", \"activation\", \"max_iter\", \"learning_rate\"]\n",
    ")\n",
    "rf_best_params = pd.DataFrame(\n",
    "    columns=[\"n_estimators\", \"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\"]\n",
    ")\n",
    "gb_best_params = pd.DataFrame(\n",
    "    columns=[\"n_estimators\", \"loss\", \"learning_rate\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\"]\n",
    ")\n",
    "\n",
    "for i in range(1):\n",
    "    # shuffle and split the data\n",
    "    shuffled_data = ShuffleuSplit(df_dados)\n",
    "\n",
    "    # KNR Execution\n",
    "    knr_rsme, knr_model, *knr_params = KNN_regression(*shuffled_data)\n",
    "    knr_best_params.loc[len(knr_best_params.index)] = knr_params\n",
    "\n",
    "    # show confusion matrix for KNN\n",
    "    # knn_test_pred = knr_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nKNN Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", knr_rsme)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], knn_test_pred))\n",
    "\n",
    "    # SVR Execution\n",
    "    svr_rsme, svr_model, *svr_params = SVM_regression(*shuffled_data)\n",
    "    svr_best_params.loc[len(svr_best_params.index)] = svr_params\n",
    "\n",
    "    #show confusion matrix for SVM\n",
    "    # svm_test_pred = svr_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nSVM Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", svr_rsme)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], svm_test_pred))\n",
    "\n",
    "    # MLP Execution\n",
    "    mlp_rsme, mlp_model, *mlp_params = MLP_regression(*shuffled_data)\n",
    "    mlp_best_params.loc[len(mlp_best_params.index)] = mlp_params\n",
    "\n",
    "    # show confusion matrix for MLP\n",
    "    # mlp_test_pred = mlp_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nMLP Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", mlp_rsme)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], mlp_test_pred))\n",
    "\n",
    "\n",
    "    # # RF Execution\n",
    "    # rf_rsme, rf_model, *rf_params = RandomForestRegression(*shuffled_data)\n",
    "    # rf_best_params.loc[len(rf_best_params.index)] = rf_params\n",
    "\n",
    "    # show confusion matrix for RF\n",
    "    # rf_test_pred = rf_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nRF Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", rf_rsme)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], rf_test_pred))\n",
    "\n",
    "\n",
    "    # # GB Execution\n",
    "    # gb_rsme, gb_model, *gb_params = GradientBoostingRegression(*shuffled_data)\n",
    "    # gb_best_params.loc[len(gb_best_params.index)] = gb_params\n",
    "\n",
    "    # show confusion matrix for GB\n",
    "    # gb_test_pred = gb_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nGB Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", gb_rsme)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], gb_test_pred))\n",
    "    \n",
    "    # MLR Execution\n",
    "    mlr_rmse = LinearRegressionMultiple(*shuffled_data)\n",
    "\n",
    "    #add accuracies to output\n",
    "    output.loc[len(output.index)] = [\n",
    "        knr_rsme,\n",
    "        svr_rsme,\n",
    "        mlp_rsme,\n",
    "        # rf_rsme,\n",
    "        # gb_rsme,\n",
    "        mlr_rmse\n",
    "    ]\n",
    "\n",
    "    # print current index and current line\n",
    "    print(\"============================================\")\n",
    "    print(\n",
    "        i,\n",
    "        \":\",\n",
    "        [\n",
    "            knr_rsme,\n",
    "            svr_rsme,\n",
    "            mlp_rsme,\n",
    "            # rf_rsme,\n",
    "            # gb_rsme,\n",
    "            mlr_rmse\n",
    "        ],\n",
    "    )\n",
    "    print(\"============================================\")\n",
    "\n",
    "\n",
    "# generate csv from knn best params, ignoring the index columns\n",
    "knr_best_params.to_csv(\"best_params/knn.csv\", index=False)\n",
    "mlp_best_params.to_csv(\"best_params/mlp.csv\", index=False)\n",
    "svr_best_params.to_csv(\"best_params/svm.csv\", index=False)\n",
    "# rf_best_params.to_csv(\"best_params/rf.csv\", index=False)\n",
    "# gb_best_params.to_csv(\"best_params/gb.csv\", index=False)\n",
    "\n",
    "# generate csv from output, ignoring the index columns\n",
    "output.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
