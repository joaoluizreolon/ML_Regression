{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/winequality-red'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\CoordCComp\\Documents\\ML_Regression\\trab-3.ipynb Célula 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/CoordCComp/Documents/ML_Regression/trab-3.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dados \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mData/winequality-red\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/CoordCComp/Documents/ML_Regression/trab-3.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_dados \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(dados)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/CoordCComp/Documents/ML_Regression/trab-3.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#Pearson Correlation in df_dados\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/winequality-red'"
     ]
    }
   ],
   "source": [
    "dados = pd.read_csv(\"Data/winequality-red\")\n",
    "df_dados = pd.DataFrame(dados)\n",
    "\n",
    "#Pearson Correlation in df_dados\n",
    "cor = df_dados.corr()\n",
    "\n",
    "#Print the correlation matrix\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data and split it into train, validation and test sets\n",
    "def ShuffleuSplit(df_dados):\n",
    "    # shuffle data to avoid bias\n",
    "    df_dados = shuffle(df_dados)\n",
    "\n",
    "    # separe the last column in another variable\n",
    "    df_dados_without_class = df_dados.drop(columns=[\"Class\"])\n",
    "\n",
    "    x_treino, x_temp, y_treino, y_temp = train_test_split(\n",
    "        df_dados_without_class,\n",
    "        df_dados[\"Class\"],\n",
    "        test_size=0.5,\n",
    "        stratify=df_dados[\"Class\"],\n",
    "    )\n",
    "    x_validacao, x_teste, y_validacao, y_teste = train_test_split(\n",
    "        x_temp, y_temp, test_size=0.5, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    # print(\"Treino\")\n",
    "    # x_treino.info()\n",
    "    # y_treino.info()\n",
    "\n",
    "    # print(\"\\nValidação\")\n",
    "    # x_validacao.info()\n",
    "    # y_validacao.info()\n",
    "\n",
    "    # print(\"\\nTeste\")\n",
    "    # x_teste.info()\n",
    "    # y_teste.info()\n",
    "    return (\n",
    "        x_treino,\n",
    "        y_treino,\n",
    "        x_validacao,\n",
    "        y_validacao,\n",
    "        x_teste,\n",
    "        y_teste,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Roc Curve\n",
    "def plot_roc_curve(fper, tper, cor, classsificador):\n",
    "    plt.clf()\n",
    "    plt.plot(fper, tper, color=cor, label=classsificador)\n",
    "    plt.plot([0, 1], [0, 1], color=\"green\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
    "    plt.ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
    "    plt.title(\"Curva ROC\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def grid_search_KNN(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    best_accuracy = -1\n",
    "    best_k = -1\n",
    "    best_distance_metric = \"\"\n",
    "    best_KNN = None\n",
    "\n",
    "    for k in range(1, 50, 2):\n",
    "        for distance_metric in [\"uniform\", \"distance\"]:\n",
    "            knn_instance = KNeighborsClassifier(\n",
    "                n_jobs=-1, n_neighbors=k, weights=distance_metric\n",
    "            )\n",
    "            knn_instance.fit(x_treino, y_treino)\n",
    "            knn_validation_pred = knn_instance.predict(x_validacao)\n",
    "            accuracy = accuracy_score(y_validacao, knn_validation_pred)\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_k = k\n",
    "                best_distance_metric = distance_metric\n",
    "                best_KNN = knn_instance\n",
    "\n",
    "    return best_KNN, best_k, best_distance_metric\n",
    "\n",
    "\n",
    "def KNN(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_KNN, best_k, best_distance_metric = grid_search_KNN(\n",
    "        x_treino, y_treino, x_validacao, y_validacao\n",
    "    )\n",
    "\n",
    "    knn_test_pred = best_KNN.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, knn_test_pred)\n",
    "\n",
    "    return test_accuracy, best_KNN, best_k, best_distance_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def grid_search_DT(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    param_grid = {\n",
    "        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"max_depth\": range(1, 33, 2),\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    }\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    best_DT = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        # print(f\"Testing parameters: {params}\")\n",
    "        DT = DecisionTreeClassifier(**params)\n",
    "        DT.fit(x_treino, y_treino)\n",
    "        dt_validation_pred = DT.predict(x_validacao)\n",
    "        accuracy = accuracy_score(y_validacao, dt_validation_pred)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "            best_DT = DT\n",
    "\n",
    "    return best_DT, best_params\n",
    "\n",
    "\n",
    "def DT(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_DT, best_params = grid_search_DT(x_treino, y_treino, x_validacao, y_validacao)\n",
    "\n",
    "    dt_test_pred = best_DT.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, dt_test_pred)\n",
    "\n",
    "    return test_accuracy, best_DT, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def grid_search_SVM(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    param_grid = {\n",
    "        \"C\": [0.1, 1.0, 10.0],  # Define C values\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    }\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    best_SVM = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        SVM = SVC(**params, probability=True)\n",
    "        SVM.fit(x_treino, y_treino)\n",
    "        svm_validation_pred = SVM.predict(x_validacao)\n",
    "        accuracy = accuracy_score(y_validacao, svm_validation_pred)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "            best_SVM = SVM\n",
    "\n",
    "    return best_SVM, best_params\n",
    "\n",
    "\n",
    "def SVM(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_SVM, best_params = grid_search_SVM(\n",
    "        x_treino, y_treino, x_validacao, y_validacao\n",
    "    )\n",
    "\n",
    "    svm_test_pred = best_SVM.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, svm_test_pred)\n",
    "\n",
    "    return test_accuracy, best_SVM, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def NB(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    NB = GaussianNB()\n",
    "    NB.fit(x_treino, y_treino)\n",
    "\n",
    "    nb_predict_test = NB.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, nb_predict_test)\n",
    "\n",
    "    return test_accuracy, NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def grid_search_MLP(x_treino, y_treino, x_validacao, y_validacao):\n",
    "    param_grid = {\n",
    "        \"hidden_layer_sizes\": [\n",
    "            (100,),\n",
    "            (50, 50),\n",
    "            (100, 50, 25),\n",
    "        ],  # Define hidden_layer_sizes\n",
    "        \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "        \"max_iter\": [1000, 2000],  # Define max_iter values\n",
    "        \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    }\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    best_MLP = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        MLP = MLPClassifier(**params)\n",
    "        MLP.fit(x_treino, y_treino)\n",
    "        mlp_validation_pred = MLP.predict(x_validacao)\n",
    "        accuracy = accuracy_score(y_validacao, mlp_validation_pred)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "            best_MLP = MLP\n",
    "\n",
    "    return best_MLP, best_params\n",
    "\n",
    "\n",
    "def MLP(x_treino, y_treino, x_validacao, y_validacao, x_teste, y_teste):\n",
    "    best_MLP, best_params = grid_search_MLP(\n",
    "        x_treino, y_treino, x_validacao, y_validacao\n",
    "    )\n",
    "\n",
    "    mlp_test_pred = best_MLP.predict(x_teste)\n",
    "    test_accuracy = accuracy_score(y_teste, mlp_test_pred)\n",
    "\n",
    "    return test_accuracy, best_MLP, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Borda Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BordaCountClassifier:\n",
    "    def __init__(self, estimators):\n",
    "        \"\"\"\n",
    "        Initialize the BordaCountClassifier.\n",
    "\n",
    "        Parameters:\n",
    "        - estimators: List of classifiers.\n",
    "        \"\"\"\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit each estimator to the data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Features.\n",
    "        - y: Target labels.\n",
    "        \"\"\"\n",
    "        for _, estimator in self.estimators:\n",
    "            estimator.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels using the Borda Count approach.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Features.\n",
    "\n",
    "        Returns:\n",
    "        - Predicted class labels.\n",
    "        \"\"\"\n",
    "        all_probs = [estimator.predict_proba(X) for _, estimator in self.estimators]\n",
    "        all_probs = np.stack(all_probs)\n",
    "\n",
    "        # Get rankings for each classifier's predictions\n",
    "        rankings = np.argsort(-all_probs, axis=-1)\n",
    "\n",
    "        # Assign points based on rankings\n",
    "        num_classes = all_probs.shape[2]\n",
    "        points = np.zeros_like(rankings)\n",
    "        for rank in range(num_classes):\n",
    "            points[rankings == rank] = num_classes - 1 - rank\n",
    "\n",
    "        # Sum points across classifiers\n",
    "        total_points = points.sum(axis=0)\n",
    "\n",
    "        # Get the final prediction as the class with the highest total points\n",
    "        final_predictions = np.argmax(total_points, axis=1)\n",
    "\n",
    "        return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "['bus' 'opel' 'saab' 'van']\n",
      "============================================\n",
      "============================================\n",
      "0 : [0.6179245283018868, 0.6462264150943396, 0.419811320754717, 0.7405660377358491, 0.6745283018867925, 0.6839622641509434, 0.6698113207547169, 0.4339622641509434]\n",
      "============================================\n",
      "============================================\n",
      "1 : [0.5990566037735849, 0.6415094339622641, 0.41037735849056606, 0.7594339622641509, 0.6745283018867925, 0.7028301886792453, 0.7311320754716981, 0.44339622641509435]\n",
      "============================================\n",
      "============================================\n",
      "2 : [0.5849056603773585, 0.6320754716981132, 0.4858490566037736, 0.7877358490566038, 0.6226415094339622, 0.6792452830188679, 0.6886792452830188, 0.4056603773584906]\n",
      "============================================\n",
      "============================================\n",
      "3 : [0.6556603773584906, 0.7405660377358491, 0.419811320754717, 0.7924528301886793, 0.7122641509433962, 0.7735849056603774, 0.7641509433962265, 0.49528301886792453]\n",
      "============================================\n",
      "============================================\n",
      "4 : [0.5849056603773585, 0.7358490566037735, 0.4528301886792453, 0.7971698113207547, 0.6745283018867925, 0.7594339622641509, 0.7122641509433962, 0.4528301886792453]\n",
      "============================================\n",
      "============================================\n",
      "5 : [0.6415094339622641, 0.6886792452830188, 0.4481132075471698, 0.7877358490566038, 0.6933962264150944, 0.7405660377358491, 0.7169811320754716, 0.46226415094339623]\n",
      "============================================\n",
      "============================================\n",
      "6 : [0.6084905660377359, 0.7028301886792453, 0.42452830188679247, 0.7311320754716981, 0.5990566037735849, 0.6933962264150944, 0.7452830188679245, 0.4858490566037736]\n",
      "============================================\n",
      "============================================\n",
      "7 : [0.5660377358490566, 0.6839622641509434, 0.5188679245283019, 0.7783018867924528, 0.6698113207547169, 0.7264150943396226, 0.7028301886792453, 0.4811320754716981]\n",
      "============================================\n",
      "============================================\n",
      "8 : [0.5707547169811321, 0.6933962264150944, 0.42924528301886794, 0.8301886792452831, 0.6981132075471698, 0.6981132075471698, 0.75, 0.44339622641509435]\n",
      "============================================\n",
      "============================================\n",
      "9 : [0.6886792452830188, 0.7169811320754716, 0.5047169811320755, 0.7877358490566038, 0.6462264150943396, 0.7735849056603774, 0.7452830188679245, 0.419811320754717]\n",
      "============================================\n",
      "============================================\n",
      "10 : [0.6698113207547169, 0.7169811320754716, 0.4811320754716981, 0.8018867924528302, 0.6981132075471698, 0.7405660377358491, 0.7452830188679245, 0.4716981132075472]\n",
      "============================================\n",
      "============================================\n",
      "11 : [0.6745283018867925, 0.7216981132075472, 0.39622641509433965, 0.8160377358490566, 0.6933962264150944, 0.7783018867924528, 0.75, 0.4858490566037736]\n",
      "============================================\n",
      "============================================\n",
      "12 : [0.589622641509434, 0.7122641509433962, 0.4339622641509434, 0.7641509433962265, 0.6320754716981132, 0.7264150943396226, 0.7216981132075472, 0.4811320754716981]\n",
      "============================================\n",
      "============================================\n",
      "13 : [0.6179245283018868, 0.7028301886792453, 0.5, 0.7688679245283019, 0.7216981132075472, 0.7594339622641509, 0.6933962264150944, 0.4811320754716981]\n",
      "============================================\n",
      "============================================\n",
      "14 : [0.589622641509434, 0.6698113207547169, 0.4386792452830189, 0.7641509433962265, 0.6556603773584906, 0.7028301886792453, 0.7075471698113207, 0.45754716981132076]\n",
      "============================================\n",
      "============================================\n",
      "15 : [0.6132075471698113, 0.7169811320754716, 0.46226415094339623, 0.7688679245283019, 0.6981132075471698, 0.7216981132075472, 0.7169811320754716, 0.49528301886792453]\n",
      "============================================\n",
      "============================================\n",
      "16 : [0.6886792452830188, 0.7122641509433962, 0.4858490566037736, 0.8254716981132075, 0.6886792452830188, 0.7641509433962265, 0.7594339622641509, 0.49528301886792453]\n",
      "============================================\n",
      "============================================\n",
      "17 : [0.6320754716981132, 0.660377358490566, 0.47641509433962265, 0.8113207547169812, 0.6745283018867925, 0.7924528301886793, 0.7594339622641509, 0.5141509433962265]\n",
      "============================================\n",
      "============================================\n",
      "18 : [0.6509433962264151, 0.7028301886792453, 0.46226415094339623, 0.7405660377358491, 0.6556603773584906, 0.7311320754716981, 0.7075471698113207, 0.5]\n",
      "============================================\n",
      "============================================\n",
      "19 : [0.5990566037735849, 0.6886792452830188, 0.45754716981132076, 0.8066037735849056, 0.6745283018867925, 0.7405660377358491, 0.7169811320754716, 0.41037735849056606]\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "output = pd.DataFrame(columns=[\"KNN\", \"DT\", \"NB\", \"SVM\", \"MLP\", \"MV\", \"SV\", \"BC\"])\n",
    "\n",
    "knn_best_params = pd.DataFrame(columns=[\"K\", \"Distance Metric\"])\n",
    "dt_best_params = pd.DataFrame(\n",
    "    columns=[\"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\"]\n",
    ")\n",
    "svm_best_params = pd.DataFrame(columns=[\"C\", \"kernel\"])\n",
    "mlp_best_params = pd.DataFrame(\n",
    "    columns=[\"hidden_layer_sizes\", \"activation\", \"max_iter\", \"learning_rate\"]\n",
    ")\n",
    "\n",
    "## find the number of elements of each class in the dataset\n",
    "print(\"============================================\")\n",
    "print(le.classes_)\n",
    "print(\"============================================\")\n",
    "\n",
    "for i in range(20):\n",
    "    shuffled_data = ShuffleuSplit(df_dados)\n",
    "\n",
    "    # KNN Execution\n",
    "    knn_accuracy, knn_model, *knn_params = KNN(*shuffled_data)\n",
    "    knn_best_params.loc[len(knn_best_params.index)] = knn_params\n",
    "\n",
    "    # # show confusion matrix for KNN\n",
    "    # knn_test_pred = knn_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nKNN Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", knn_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], knn_test_pred))\n",
    "\n",
    "    # DT Execution\n",
    "    dt_accuracy, dt_model, dt_params = DT(*shuffled_data)\n",
    "    dt_params = [\n",
    "        dt_params[key]\n",
    "        for key in [\"criterion\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\"]\n",
    "    ]\n",
    "    dt_best_params.loc[len(dt_best_params.index)] = dt_params\n",
    "\n",
    "    # # show confusion matrix for DT\n",
    "    # dt_test_pred = dt_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nDT Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", dt_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], dt_test_pred))\n",
    "\n",
    "    # SVM Execution\n",
    "    svm_accuracy, svm_model, svm_params = SVM(*shuffled_data)\n",
    "    svm_params = [svm_params[key] for key in [\"C\", \"kernel\"]]\n",
    "    svm_best_params.loc[len(svm_best_params.index)] = svm_params\n",
    "\n",
    "    # # show confusion matrix for SVM\n",
    "    # svm_test_pred = svm_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nSVM Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", svm_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], svm_test_pred))\n",
    "\n",
    "    # NB Execution\n",
    "    nb_accuracy, nb_model = NB(*shuffled_data)\n",
    "\n",
    "    # # show confusion matrix for NB\n",
    "    # nb_test_pred = nb_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nNB Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", nb_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], nb_test_pred))\n",
    "\n",
    "    # MLP Execution\n",
    "    mlp_accuracy, mlp_model, mlp_params = MLP(*shuffled_data)\n",
    "    mlp_params = [\n",
    "        mlp_params[key]\n",
    "        for key in [\"hidden_layer_sizes\", \"activation\", \"max_iter\", \"learning_rate\"]\n",
    "    ]\n",
    "    mlp_best_params.loc[len(mlp_best_params.index)] = mlp_params\n",
    "\n",
    "    # # show confusion matrix for MLP\n",
    "    # mlp_test_pred = mlp_model.predict(shuffled_data[4])\n",
    "    # print(\"\\nMLP Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", mlp_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], mlp_test_pred))\n",
    "\n",
    "    # create a multiple classifier approach with VotingClassifier\n",
    "    estimators = [\n",
    "        (\"knn\", knn_model),\n",
    "        (\"dt\", dt_model),\n",
    "        (\"nb\", nb_model),\n",
    "        (\"svm\", svm_model),\n",
    "        (\"mlp\", mlp_model),\n",
    "    ]\n",
    "\n",
    "    # majority voting\n",
    "    majority_voting_classifier = VotingClassifier(estimators=estimators, voting=\"hard\")\n",
    "    majority_voting_classifier.fit(shuffled_data[0], shuffled_data[1])\n",
    "\n",
    "    voting_test_pred = majority_voting_classifier.predict(shuffled_data[4])\n",
    "    majority_voting_accuracy = accuracy_score(shuffled_data[5], voting_test_pred)\n",
    "\n",
    "    # print(\"\\nMajority Rule Voting Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", majority_voting_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], voting_test_pred))\n",
    "\n",
    "    # sum voting\n",
    "    sum_voting_classifier = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "    sum_voting_classifier.fit(shuffled_data[0], shuffled_data[1])\n",
    "\n",
    "    voting_test_pred = sum_voting_classifier.predict(shuffled_data[4])\n",
    "    sum_voting_accuracy = accuracy_score(shuffled_data[5], voting_test_pred)\n",
    "\n",
    "    # print(\"\\nSum Rule Voting Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", sum_voting_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], voting_test_pred))\n",
    "\n",
    "    # borda count\n",
    "    borda_clf = BordaCountClassifier(estimators=estimators)\n",
    "    borda_clf.fit(shuffled_data[0], shuffled_data[1])\n",
    "    borda_count_predictions = borda_clf.predict(shuffled_data[4])\n",
    "    bc_accuracy = accuracy_score(shuffled_data[5], borda_count_predictions)\n",
    "\n",
    "    # print(\"\\nBorda Count Confusion Matrix:\")\n",
    "    # print(\"Accuracy: \", bc_accuracy)\n",
    "    # print(metrics.confusion_matrix(shuffled_data[5], borda_count_predictions))\n",
    "\n",
    "    # add accuracies to output\n",
    "    output.loc[len(output.index)] = [\n",
    "        knn_accuracy,\n",
    "        dt_accuracy,\n",
    "        nb_accuracy,\n",
    "        svm_accuracy,\n",
    "        mlp_accuracy,\n",
    "        majority_voting_accuracy,\n",
    "        sum_voting_accuracy,\n",
    "        bc_accuracy,\n",
    "    ]\n",
    "\n",
    "    # print current index and current line\n",
    "    print(\"============================================\")\n",
    "    print(\n",
    "        i,\n",
    "        \":\",\n",
    "        [\n",
    "            knn_accuracy,\n",
    "            dt_accuracy,\n",
    "            nb_accuracy,\n",
    "            svm_accuracy,\n",
    "            mlp_accuracy,\n",
    "            majority_voting_accuracy,\n",
    "            sum_voting_accuracy,\n",
    "            bc_accuracy,\n",
    "        ],\n",
    "    )\n",
    "    print(\"============================================\")\n",
    "\n",
    "\n",
    "# generate csv from knn best params, ignoring the index columns\n",
    "knn_best_params.to_csv(\"best_params/knn.csv\", index=False)\n",
    "dt_best_params.to_csv(\"best_params/dt.csv\", index=False)\n",
    "svm_best_params.to_csv(\"best_params/svm.csv\", index=False)\n",
    "mlp_best_params.to_csv(\"best_params/mlp.csv\", index=False)\n",
    "\n",
    "# generate csv from output, ignoring the index columns\n",
    "output.to_csv(\"output.csv\", inde x=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
